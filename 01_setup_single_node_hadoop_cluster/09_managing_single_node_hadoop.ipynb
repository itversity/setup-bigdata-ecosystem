{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Single Node Hadoop\n",
    "\n",
    "As part of this topic, I will cover how to manage single node hadoop that is setup using Ubuntu 18.04 on GCP.\n",
    "* We need to shutdown the server when it is not in use. If you do not shutdown, you will end up paying more money to GCP or you will run out of credits faster.\n",
    "* If you shutdown server using GCP web console with out shutting down HDFS, then the HDFS might get corrupted.\n",
    "* Here are the steps you are supposed to follow to ensure that HDFS is not corrupted when you shutdown the Ubuntu 18.04 server. You need to follow the below order.\n",
    "  * Make sure yarn is stopped by running `stop-yarn.sh`.\n",
    "  * Make sure HDFS is stopped by running `stop-hdfs.sh`.\n",
    "  * Now, you can shutdown the server using GCP Web Console.\n",
    "* Also, if you want to use Hadoop when the server is up - you need to ensure that both HDFS and YARN are started. You can run these commands in this order to start the services.\n",
    "\n",
    "```shell\n",
    "start-dfs.sh\n",
    "start-yarn.sh\n",
    "jps\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
